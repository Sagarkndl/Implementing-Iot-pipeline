{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d78f37b-bf66-4a80-a7ae-164065a6bc01",
   "metadata": {},
   "source": [
    "# ML 1/2 – TensorFlow Foundations\n",
    "\n",
    "This notebook covers:\n",
    "- Tensors and numerical operations\n",
    "- Regression with neural networks\n",
    "- Classification models\n",
    "- CNN basics\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232e1afd-4efc-4f6e-8472-d0eed28cfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() (3,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "#Tensor basics\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "scalar = tf.constant(7)\n",
    "vector = tf.constant([10,20,30])\n",
    "matrix = tf.constant([[1.,2.],[3.,4.]])\n",
    "\n",
    "print(scalar.shape, vector.shape, matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6161f87-1db7-4c17-a750-4f9db7c51c24",
   "metadata": {},
   "source": [
    "Scalars are rank-0 tensors, vectors are rank-1, and matrices are rank-2.\n",
    "Shape errors are common in deep learning so checking tensor dimensions is important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788d2b55-e8a3-4f43-9693-6250769b4fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[20. 17.]\n",
      " [13. 14.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[20. 14.]\n",
      " [ 6.  8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix operations\n",
    "A = tf.constant([[10.,7.],[3.,4.]])\n",
    "print(A + 10)\n",
    "print(A * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0326593-8821-4a3d-9fe0-dc6dcd4ef62f",
   "metadata": {},
   "source": [
    "TensorFlow supports broadcasting which allows scalar values to operate across tensors efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bff857-fcf1-4fe9-85e9-069f173e5eab",
   "metadata": {},
   "source": [
    "## Regression: Learning y = x + 10\n",
    "\n",
    "A simple neural network can learn a linear function by adjusting its weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800ed7fe-4d74-41ce-96c4-222d4f5bd5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Käyttäjä\\Desktop\\Implementing-Iot-pipeline\\ml\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 16.1856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.18558692932129"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.arange(-20, 21, 2, dtype=np.float32)\n",
    "y = X + 10\n",
    "\n",
    "X_train, y_train = X[:20], y[:20]\n",
    "X_test, y_test = X[20:], y[20:]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mae\", optimizer=\"sgd\")\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915941e-0b6a-4264-adc0-6f1ec2b9c6a6",
   "metadata": {},
   "source": [
    "The model learns the linear relationship rather than memorizing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3976d92-4190-4c67-9499-81be7c2916d4",
   "metadata": {},
   "source": [
    "## Binary Classification on Non-linear Data\n",
    "\n",
    "Non-linear activation functions allow neural networks to learn curved decision boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f803857e-1c4c-44ca-945f-f44f467d3f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.5507 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5506690740585327, 0.9950000047683716]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_circles(n_samples=1000, noise=0.03)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\", input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=25, verbose=0)\n",
    "\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03168788-8344-4109-8982-367bbc182455",
   "metadata": {},
   "source": [
    "ReLU introduces non-linearity which makes complex decision boundaries possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4bbd5-d5a3-42f9-9bd2-7ce3be377fba",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks for Images\n",
    "\n",
    "CNNs preserve spatial structure and learn local visual features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1655d05-c4a6-4773-b919-19ca7e68c190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Käyttäjä\\Desktop\\Implementing-Iot-pipeline\\ml\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8230 - loss: 0.5041 - val_accuracy: 0.8657 - val_loss: 0.3847\n",
      "Epoch 2/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8749 - loss: 0.3619 - val_accuracy: 0.8733 - val_loss: 0.3502\n",
      "Epoch 3/3\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8876 - loss: 0.3252 - val_accuracy: 0.8805 - val_loss: 0.3317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22579c0ca70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train[...,None]/255.0\n",
    "x_test = x_test[...,None]/255.0\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,3,activation=\"relu\",input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=3, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cc61c-03f1-4a45-8ab6-61d79303e5d4",
   "metadata": {},
   "source": [
    "Convolution layers extract spatial features while pooling improves generalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
