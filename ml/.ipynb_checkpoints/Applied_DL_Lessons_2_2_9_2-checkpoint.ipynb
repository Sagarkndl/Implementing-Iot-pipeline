{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437ca34b",
   "metadata": {},
   "source": [
    "# Applied Deep Learning with TensorFlow\n",
    "## Lessons 2.2 and 9.2\n",
    "\n",
    "This notebook implements and verifies the code examples after environment setup.\n",
    "It includes explanatory note blocks between code sections.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9e848",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import required libraries and verify TensorFlow installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Num GPUs Available:', len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7427b8",
   "metadata": {},
   "source": [
    "---\n",
    "# Lesson 2.2 – Tensor and Numerical Foundations\n",
    "\n",
    "In this section we:\n",
    "- Create tensors of different ranks\n",
    "- Inspect shape and dtype\n",
    "- Perform matrix multiplication\n",
    "- Use aggregation functions\n",
    "\n",
    "Key idea: Most deep learning errors come from shape mismatches, not math mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalars, vectors, matrices\n",
    "scalar = tf.constant(7)\n",
    "vector = tf.constant([10, 20, 30])\n",
    "matrix = tf.constant([[1., 2.], [3., 4.]])\n",
    "\n",
    "print('Scalar shape:', scalar.shape)\n",
    "print('Vector shape:', vector.shape)\n",
    "print('Matrix shape:', matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7057dbea",
   "metadata": {},
   "source": [
    "### Matrix Multiplication Example\n",
    "Neural networks rely heavily on matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[1., 2.], [3., 4.], [5., 6.]])\n",
    "Y = tf.constant([[7., 8.], [9., 10.], [11., 12.]])\n",
    "\n",
    "XtY = tf.matmul(X, tf.transpose(Y))\n",
    "print('Result shape:', XtY.shape)\n",
    "XtY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfedf4",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "Used to compute summary statistics such as min, max, mean, sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = tf.constant(np.random.randint(0, 100, size=10))\n",
    "\n",
    "print('Min:', tf.reduce_min(E).numpy())\n",
    "print('Max:', tf.reduce_max(E).numpy())\n",
    "print('Mean:', tf.reduce_mean(tf.cast(E, tf.float32)).numpy())\n",
    "print('Sum:', tf.reduce_sum(E).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b00df",
   "metadata": {},
   "source": [
    "---\n",
    "# Lesson 9.2 – Neural Network Classification\n",
    "\n",
    "In this section we implement a binary classification model\n",
    "on non-linearly separable data (circles dataset).\n",
    "\n",
    "Key idea: Non-linear activation functions are required\n",
    "to solve non-linear classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear data\n",
    "X, y = make_circles(n_samples=1000, noise=0.03, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411aa2fe",
   "metadata": {},
   "source": [
    "### Build and Train Model\n",
    "We use ReLU activations and sigmoid output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33de6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=25, verbose=0)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94b7e1",
   "metadata": {},
   "source": [
    "### Decision Boundary Visualization\n",
    "Visualizing predictions helps understand model behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X[:,0].min()-0.1, X[:,0].max()+0.1, 200),\n",
    "    np.linspace(X[:,1].min()-0.1, X[:,1].max()+0.1, 200)\n",
    ")\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = model.predict(grid, verbose=0).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(xx, yy, (probs>0.5).astype(int), alpha=0.6)\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test)\n",
    "plt.title('Binary Classification Decision Boundary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
